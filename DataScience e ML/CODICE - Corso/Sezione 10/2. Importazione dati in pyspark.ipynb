{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# caricare i dati sulla sessione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark \n",
    "findspark.init(\"/Users/valentinaporcu/spark/spark-2.4.1-bin-hadoop2.7\")\n",
    "import pyspark \n",
    "from pyspark.sql import DataFrameNaFunctions \n",
    "from pyspark.sql.functions import lit \n",
    "from pyspark.ml.feature import StringIndexer  \n",
    "from pyspark.sql.types import StructType, StructField, StringType, LongType\n",
    "from pyspark.ml import Pipeline \n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importare dati in pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# struttura di base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.format(\"csv\") \n",
    ".option(\" mode\", \"FAILFAST\") \n",
    ".option(\" inferSchema\", \"true\") \n",
    ".option(\" path\", \"path/ to/ file( s)\") \n",
    ".schema(schema1) \n",
    ".load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema\n",
    "\n",
    "fields = [StructField('name', StringType(), True),\n",
    "          StructField('math', LongType(), True),\n",
    "          StructField('english', LongType(), True),\n",
    "          StructField('science', LongType(), True),\n",
    "\n",
    "schema = StructType(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(df1, schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# caricare un file json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json1 = (\n",
    "    spark\n",
    "    .read\n",
    "    .json('../file.json')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oppure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json2 = spark.read.load('path', format = 'json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = [\n",
    "    '{\"Date\":\"2018-05-10\",\"Name\":\"Laura\",\"Age\":28,\"Work\":\"restorer\",\"Location\":\"Paris\"}', \n",
    "    '{\"Date\":\"2017-11-01\",\"Name\":\"Francis\",\"Age\":34 ,\"Work\":\"doctor\" ,\"Location\":\"Rome\"}', \n",
    "    '{\"Date\":\"2016-07-02\",\"Name\":\"Simon\"  ,\"Age\":56,\"Work\":\"teacher\",\"Location\":\"Dublim\"}', \n",
    "    '{\"Date\":\"2018-12-31\",\"Name\":\"Kate\"  ,\"Age\":45 ,\"Work\":\"programmer\" ,\"Location\":\"London\"}'\n",
    "]\n",
    "\n",
    "simple_df_json = spark.read.json(sc.parallelize(json_string))\n",
    "simple_df_json.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# caricare un file in csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv = (\n",
    "    spark\n",
    "    .read\n",
    "    .csv(\n",
    "        '../Data/DataFrames_sample.csv'\n",
    "        , header=True\n",
    "        , inferSchema=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv = spark.read.csv('pid.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv2 = spark.read.options(header='true',inferSchema='true').csv(\"cars.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in .txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_txt = spark.read.text('nome_file.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parquet = spark.read.load(\"path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parquet2 = spark.read.parquet('path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# altri formati sono lo XML, AVRO, OCR, JDBC eccetera..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrivere file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.json(\"json_dir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.format(\"json\").save(\"json_dir2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json.write.json(\"newjson_dir\")\n",
    "df_json.write.format(\"json\").save(\"newjson_dir2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json.write.parquet(\"parquet_dir\")\n",
    "df_json.write.format(\"parquet\").save(\"parquet_dir2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
