{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark \n",
    "findspark.init(\"/Users/valentinaporcu/spark/spark-2.4.1-bin-hadoop2.7\")\n",
    "import pyspark \n",
    "from pyspark.sql import DataFrameNaFunctions \n",
    "from pyspark.sql.functions import lit \n",
    "from pyspark.ml.feature import StringIndexer  \n",
    "from pyspark.ml import Pipeline \n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"nlp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('/Users/valentinaporcu/Dropbox/topic/12.\\ Guida\\ ai\\ Big\\ Data\\ con\\ Python/codice\\ -\\ guida\\ ai\\ big\\ data\\ con\\ Python/Sezione\\ 3/churn.csv',\n",
    "                      inferSchema=True,\n",
    "                      header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+-----------+---------+-----+\n",
      "|_c0|gender|age|  paymethod|lasttrans|label|\n",
      "+---+------+---+-----------+---------+-----+\n",
      "|565|  male| 32|credit card|       86|loyal|\n",
      "|846|female| 44|credit card|       89|churn|\n",
      "|666|  male| 70|       cash|      123|loyal|\n",
      "|970|female| 21|credit card|      102|loyal|\n",
      "|181|female| 53|credit card|      142|   NA|\n",
      "|987|  male| 81|       cash|      153|   NA|\n",
      "|789|female| 63|       cash|       89|loyal|\n",
      "|  6|female| 47|       cash|      142|loyal|\n",
      "| 47|female| 61|   bancomat|      117|churn|\n",
      "|929|  male| 19|   bancomat|      108|loyal|\n",
      "|570|female| 76|credit card|      162|churn|\n",
      "|296|  male| 46|credit card|       95|   NA|\n",
      "|798|  male| 53|credit card|       54|loyal|\n",
      "|960|  male| 27|       cash|      130|   NA|\n",
      "|748|  male| 27|credit card|       70|loyal|\n",
      "|339|  male| 52|credit card|       77|loyal|\n",
      "|125|  male| 34|credit card|      100|loyal|\n",
      "|409|  male| 28|credit card|       43|loyal|\n",
      "|790|female| 52|credit card|      107|loyal|\n",
      "|712|female| 33|credit card|      112|churn|\n",
      "+---+------+---+-----------+---------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0', 'gender', 'age', 'paymethod', 'lasttrans', 'label']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.na.drop(how ='any').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(df[\"label\"] != 'NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexer = StringIndexer(inputCol= \"gender\", outputCol=\"genderIndex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(df) for column in list(set(df.columns)-set(['_c0', 'age', 'lasttrans'])) ]\n",
    "\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "indexed = pipeline.fit(df).transform(df)\n",
    "\n",
    "indexed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols = ['age',\n",
    " 'lasttrans',\n",
    " 'gender_index',\n",
    " 'paymethod_index'], outputCol = \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = assembler.transform(indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df = output.select('features','label_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = transformed_df.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NaiveBayes(labelCol='label_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = nb.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_predictions = nb_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction', \n",
    "                                          labelCol='label_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_acc = evaluator.evaluate(nb_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
